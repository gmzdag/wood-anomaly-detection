# -*- coding: utf-8 -*-
"""GLASS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B_Yia6sUouXUmmrs-mWdhtQUYkC-cSBB

#GLASS

Bu notebook'ta, ahşap yüzeylerdeki anomalileri tespit etmek için bir *GLASS* modeli geliştirilecek ve eğitilecektir.

## 1. Ortam Kurulumu

### 1.1 Google Drive Bağlantısı
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive

"""### 1.2 GLASS Deposunun Klonlanması"""

!git clone https://github.com/gmzdag/wood-anomaly-detection.git

# Commented out IPython magic to ensure Python compatibility.
# %cd cd wood-anomaly-detection/models/GLASS/src

"""### 1.3 Gerekli Kütüphanelerin Kurulumu"""

!pip install imgaug

!pip install numpy==1.26.4

"""## 2. DTD'lerin Yüklenmesi

Anomali üretimi için kullanılacak DTD (Daha Fazla Dokulu Sözlük) veri setini hazırlanması.
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd datasets
!wget https://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz
!tar -xf dtd-r1.0.1.tar.gz
!rm dtd-r1.0.1.tar.gz

# Commented out IPython magic to ensure Python compatibility.
# %cd ..

"""##3. Model Eğitimi
GLASS modelinin ahşap veri seti üzerinde eğitilmesi.

**Parametre Açıklamaları:**

 - `--gpu:` Kullanılacak GPU'nun ID'si.
 - `--seed`: Rastgelelik için kullanılan tohum değeri. Bu, deneylerin tekrarlanabilirliğini sağlar.
 - `--test`: Test modunu etkinleştirir. Genellikle belirtilen bir checkpoint'ten (ckpt) yüklenen model ile test yapılır.
 - `net`: Model ile ilgili parametrelerin başlangıcını belirtir.
 - `-b`: Kullanılacak temel ağ (backbone network). Örnekte wideresnet50 kullanılıyor.
 - `-le`: Özellik çıkarımı için kullanılacak katman. Birden fazla belirtilebilir.
 - `--pretrain_embed_dimension`: Önceden eğitilmiş modelden çıkarılan gömülü vektörlerin (embeddings) boyutunu belirtir.
 - `--target_embed_dimension`: Hedef gömülü vektörlerin boyutunu belirtir.
 - `--patchsize`: İşlenecek görüntü yamalarının (patches) boyutu.
 - `--meta_epochs`: Meta-eğitim (meta-learning) fazındaki epoch sayısı.
 - `--eval_epochs`: Değerlendirme (evaluation) fazındaki epoch sayısı.
 - `--dsc_layers`: Diskriminatör (discriminator) ağındaki katman sayısı.
 - `--dsc_hidden`: Diskriminatör ağındaki gizli katmanların boyutu (nöron sayısı).
 - `--pre_proj`: Ön projeksiyonun kullanılıp kullanılmayacağını belirten flag veya değer.
 - `--mining`: Negatif örnek madenciliği (negative mining) stratejisinin kullanılıp kullanılmayacağını belirten flag veya değer.
 - `--noise`: Anomali ekleme veya eğitim sürecinde kullanılan gürültü (noise) miktarı.
 - `--radius`: Belirli bir algoritma veya strateji içinde kullanılan yarıçap değeri (örn. kümeleme, anomali tespiti kriteri).
 - `--p`: Olasılıkla ilgili bir parametre
 - `--step`: Bir adım boyutu .
 - `--limit`: Belirli bir sınırlama veya üst limit değeri.
 - `dataset`: Veri seti ile ilgili parametrelerin başlangıcını belirtir.
 - `--distribution`: Veri dağılımı ile ilgili bir parametre. Değer 0 olarak belirtilmiş.
 - `--mean`: Veri normalizasyonu veya işlenmesinde kullanılan ortalama (mean) değeri.
 - `--std`: Veri normalizasyonu veya işlenmesinde kullanılan standart sapma (standard deviation) değeri.
 - `--fg`: Genellikle ön plan (foreground) ile ilgili bir parametre. Değer 0 olarak belirtilmiş.
 - `--rand_aug`: Rastgele veri artırma yönteminin kullanılıp kullanılmayacağını belirten flag veya değer. Değer 1 olarak belirtilmiş, bu da kullanıldığı anlamına gelir.
 - `--batch_size`: Eğitim veya test sırasında kullanılacak veri yığınlarının (batch) boyutu.
 - `--resize`: Görüntülerin yeniden boyutlandırılacağı boyut.
 - `--imagesize`: İşlem görecek görüntülerin nihai boyutu.
  - `-d`: Kullanılacak veri setini ve ilgili yolları belirtir.
  - `wood`: Veri setinin spesifik bir objesi veya kategorisi (Ahşap).
  - `mvtec`: Kullanılan temel veri setinin adı.
  - `/content/drive/MyDrive/processed_dataset`: İşlenmiş veri setinin dosya yolu.
  - `/content/drive/MyDrive/GLASS/datasets/dtd/images`: Anomali üretimi için kullanılacak ek veri setinin (DTD) dosya yolu.

###3.1 10 Epoch İle Model Eğitimi
"""

!python main.py \
    --gpu 0 \
    --seed 0 \
    --test ckpt \
  net \
    -b wideresnet50 \
    -le layer2 \
    -le layer3 \
    --pretrain_embed_dimension 1536 \
    --target_embed_dimension 1536 \
    --patchsize 4 \
    --meta_epochs 10 \
    --eval_epochs 1 \
    --dsc_layers 2 \
    --dsc_hidden 1024 \
    --pre_proj 1 \
    --mining 1 \
    --noise 0.015 \
    --radius 0.75 \
    --p 0.5 \
    --step 20 \
    --limit 392 \
  dataset \
    --distribution 0 \
    --mean 0.5 \
    --std 0.1 \
    --fg 0 \
    --rand_aug 1 \
    --batch_size 8 \
    --resize 256 \
    --imagesize 256 -d wood mvtec /content/drive/MyDrive/processed_dataset /content/drive/MyDrive/wood-anomaly-detection/models/GLASS/src/datasets/dtd/images/

"""###3.2 20 Epoch İle Model Eğitimi"""

!python main.py \
    --gpu 0 \
    --seed 0 \
    --test ckpt \
  net \
    -b wideresnet50 \
    -le layer2 \
    -le layer3 \
    --pretrain_embed_dimension 1536 \
    --target_embed_dimension 1536 \
    --patchsize 4 \
    --meta_epochs 20 \
    --eval_epochs 1 \
    --dsc_layers 2 \
    --dsc_hidden 1024 \
    --pre_proj 1 \
    --mining 1 \
    --noise 0.015 \
    --radius 0.75 \
    --p 0.5 \
    --step 20 \
    --limit 392 \
  dataset \
    --distribution 0 \
    --mean 0.5 \
    --std 0.1 \
    --fg 0 \
    --rand_aug 1 \
    --batch_size 8 \
    --resize 256 \
    --imagesize 256 -d wood mvtec /content/drive/MyDrive/processed_dataset content/drive/MyDrive/wood-anomaly-detection/models/GLASS/src/datasets/dtd/images/

"""###3.3 30 Epoch İle Model Eğitimi"""

!python main.py \
    --gpu 0 \
    --seed 0 \
    --test ckpt \
  net \
    -b wideresnet50 \
    -le layer2 \
    -le layer3 \
    --pretrain_embed_dimension 1536 \
    --target_embed_dimension 1536 \
    --patchsize 4 \
    --meta_epochs 30 \
    --eval_epochs 1 \
    --dsc_layers 2 \
    --dsc_hidden 1024 \
    --pre_proj 1 \
    --mining 1 \
    --noise 0.015 \
    --radius 0.75 \
    --p 0.5 \
    --step 20 \
    --limit 392 \
  dataset \
    --distribution 0 \
    --mean 0.5 \
    --std 0.1 \
    --fg 0 \
    --rand_aug 1 \
    --batch_size 8 \
    --resize 256 \
    --imagesize 256 -d wood mvtec /content/drive/MyDrive/processed_dataset content/drive/MyDrive/wood-anomaly-detection/models/DRAEM/src/datasets/dtd/images/

"""###3.4 50 Epoch İle Model Eğitimi"""

!python main.py \
    --gpu 0 \
    --seed 0 \
    --test ckpt \
  net \
    -b wideresnet50 \
    -le layer2 \
    -le layer3 \
    --pretrain_embed_dimension 1536 \
    --target_embed_dimension 1536 \
    --patchsize 4 \
    --meta_epochs 50 \
    --eval_epochs 1 \
    --dsc_layers 2 \
    --dsc_hidden 1024 \
    --pre_proj 1 \
    --mining 1 \
    --noise 0.015 \
    --radius 0.75 \
    --p 0.5 \
    --step 20 \
    --limit 392 \
  dataset \
    --distribution 0 \
    --mean 0.5 \
    --std 0.1 \
    --fg 0 \
    --rand_aug 1 \
    --batch_size 8 \
    --resize 256 \
    --imagesize 256 -d wood mvtec /content/drive/MyDrive/processed_dataset /content/drive/MyDrive/GLASS/datasets/dtd/images

import os
from PIL import Image
import matplotlib.pyplot as plt

image_directory = '/content/drive/MyDrive/GLASS/results/eval/mvtec_wood'

image_files = [f for f in os.listdir(image_directory) if f.endswith('.png')]
image_files.sort()

selected_images = image_files[:5]

fig, axes = plt.subplots(len(selected_images), 1, figsize=(5, 15))

for i, image_file in enumerate(selected_images):
    image_path = os.path.join(image_directory, image_file)

    img = Image.open(image_path)

    axes[i].imshow(img)
    axes[i].set_title(image_file)
    axes[i].axis('off')

plt.tight_layout()
plt.show()